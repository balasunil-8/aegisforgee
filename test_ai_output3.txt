INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/model.safetensors "HTTP/1.1 302 Found"
INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/xet-read-token/c9745ed1d9f207416be6d2e6f8de32d1f16199bf "HTTP/1.1 200 OK"
Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]Loading weights:   1%|          | 1/103 [00:00<00:00, 7332.70it/s, Materializing param=embeddings.LayerNorm.bias]Loading weights:   1%|          | 1/103 [00:00<00:00, 1831.57it/s, Materializing param=embeddings.LayerNorm.bias]Loading weights:   2%|1         | 2/103 [00:00<00:00, 2144.33it/s, Materializing param=embeddings.LayerNorm.weight]Loading weights:   2%|1         | 2/103 [00:00<00:00, 1560.96it/s, Materializing param=embeddings.LayerNorm.weight]Loading weights:   3%|2         | 3/103 [00:00<00:00, 1476.69it/s, Materializing param=embeddings.position_embeddings.weight]Loading weights:   3%|2         | 3/103 [00:00<00:00, 1347.50it/s, Materializing param=embeddings.position_embeddings.weight]Loading weights:   4%|3         | 4/103 [00:00<00:00, 1335.66it/s, Materializing param=embeddings.token_type_embeddings.weight]Loading weights:   4%|3         | 4/103 [00:00<00:00, 1222.38it/s, Materializing param=embeddings.token_type_embeddings.weight]Loading weights:   5%|4         | 5/103 [00:00<00:00, 1417.67it/s, Materializing param=embeddings.word_embeddings.weight]      Loading weights:   5%|4         | 5/103 [00:00<00:00, 1271.16it/s, Materializing param=embeddings.word_embeddings.weight]Loading weights:   6%|5         | 6/103 [00:00<00:00, 1208.38it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]Loading weights:   6%|5         | 6/103 [00:00<00:00, 1139.86it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]Loading weights:   7%|6         | 7/103 [00:00<00:00, 1161.31it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]Loading weights:   7%|6         | 7/103 [00:00<00:00, 1114.74it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]Loading weights:   8%|7         | 8/103 [00:00<00:00, 1023.25it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      Loading weights:   8%|7         | 8/103 [00:00<00:00, 947.44it/s, Materializing param=encoder.layer.0.attention.output.dense.bias] Loading weights:   9%|8         | 9/103 [00:00<00:00, 956.34it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]Loading weights:   9%|8         | 9/103 [00:00<00:00, 942.12it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]Loading weights:  10%|9         | 10/103 [00:00<00:00, 987.71it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     Loading weights:  10%|9         | 10/103 [00:00<00:00, 964.27it/s, Materializing param=encoder.layer.0.attention.self.key.bias]Loading weights:  11%|#         | 11/103 [00:00<00:00, 1006.25it/s, Materializing param=encoder.layer.0.attention.self.key.weight]Loading weights:  11%|#         | 11/103 [00:00<00:00, 993.20it/s, Materializing param=encoder.layer.0.attention.self.key.weight] Loading weights:  12%|#1        | 12/103 [00:00<00:00, 1022.79it/s, Materializing param=encoder.layer.0.attention.self.query.bias]Loading weights:  12%|#1        | 12/103 [00:00<00:00, 1010.17it/s, Materializing param=encoder.layer.0.attention.self.query.bias]Loading weights:  13%|#2        | 13/103 [00:00<00:00, 1062.08it/s, Materializing param=encoder.layer.0.attention.self.query.weight]Loading weights:  13%|#2        | 13/103 [00:00<00:00, 1039.66it/s, Materializing param=encoder.layer.0.attention.self.query.weight]Loading weights:  14%|#3        | 14/103 [00:00<00:00, 1062.56it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  Loading weights:  14%|#3        | 14/103 [00:00<00:00, 986.07it/s, Materializing param=encoder.layer.0.attention.self.value.bias] Loading weights:  15%|#4        | 15/103 [00:00<00:00, 1013.38it/s, Materializing param=encoder.layer.0.attention.self.value.weight]Loading weights:  15%|#4        | 15/103 [00:00<00:00, 997.65it/s, Materializing param=encoder.layer.0.attention.self.value.weight] Loading weights:  16%|#5        | 16/103 [00:00<00:00, 1036.41it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]   Loading weights:  16%|#5        | 16/103 [00:00<00:00, 998.54it/s, Materializing param=encoder.layer.0.intermediate.dense.bias] Loading weights:  17%|#6        | 17/103 [00:00<00:00, 992.86it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]Loading weights:  17%|#6        | 17/103 [00:00<00:00, 950.09it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]Loading weights:  17%|#7        | 18/103 [00:00<00:00, 970.95it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    Loading weights:  17%|#7        | 18/103 [00:00<00:00, 951.60it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]Loading weights:  18%|#8        | 19/103 [00:00<00:00, 981.17it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]Loading weights:  18%|#8        | 19/103 [00:00<00:00, 954.86it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]Loading weights:  19%|#9        | 20/103 [00:00<00:00, 977.48it/s, Materializing param=encoder.layer.0.output.dense.bias]      Loading weights:  19%|#9        | 20/103 [00:00<00:00, 940.80it/s, Materializing param=encoder.layer.0.output.dense.bias]Loading weights:  20%|##        | 21/103 [00:00<00:00, 951.29it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  20%|##        | 21/103 [00:00<00:00, 943.94it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  21%|##1       | 22/103 [00:00<00:00, 962.41it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]Loading weights:  21%|##1       | 22/103 [00:00<00:00, 953.53it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]Loading weights:  22%|##2       | 23/103 [00:00<00:00, 982.00it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]Loading weights:  22%|##2       | 23/103 [00:00<00:00, 959.20it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]Loading weights:  23%|##3       | 24/103 [00:00<00:00, 982.92it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      Loading weights:  23%|##3       | 24/103 [00:00<00:00, 967.90it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]Loading weights:  24%|##4       | 25/103 [00:00<00:00, 993.89it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]Loading weights:  24%|##4       | 25/103 [00:00<00:00, 982.03it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]Loading weights:  25%|##5       | 26/103 [00:00<00:00, 998.14it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      Loading weights:  25%|##5       | 26/103 [00:00<00:00, 985.75it/s, Materializing param=encoder.layer.1.attention.self.key.bias]Loading weights:  26%|##6       | 27/103 [00:00<00:00, 1005.22it/s, Materializing param=encoder.layer.1.attention.self.key.weight]Loading weights:  26%|##6       | 27/103 [00:00<00:00, 974.81it/s, Materializing param=encoder.layer.1.attention.self.key.weight] Loading weights:  27%|##7       | 28/103 [00:00<00:00, 985.07it/s, Materializing param=encoder.layer.1.attention.self.query.bias]Loading weights:  27%|##7       | 28/103 [00:00<00:00, 980.30it/s, Materializing param=encoder.layer.1.attention.self.query.bias]Loading weights:  28%|##8       | 29/103 [00:00<00:00, 978.96it/s, Materializing param=encoder.layer.1.attention.self.query.weight]Loading weights:  28%|##8       | 29/103 [00:00<00:00, 968.98it/s, Materializing param=encoder.layer.1.attention.self.query.weight]Loading weights:  29%|##9       | 30/103 [00:00<00:00, 983.56it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  Loading weights:  29%|##9       | 30/103 [00:00<00:00, 979.15it/s, Materializing param=encoder.layer.1.attention.self.value.bias]Loading weights:  30%|###       | 31/103 [00:00<00:00, 992.04it/s, Materializing param=encoder.layer.1.attention.self.value.weight]Loading weights:  30%|###       | 31/103 [00:00<00:00, 987.91it/s, Materializing param=encoder.layer.1.attention.self.value.weight]Loading weights:  31%|###1      | 32/103 [00:00<00:00, 1013.08it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]   Loading weights:  31%|###1      | 32/103 [00:00<00:00, 1006.28it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]Loading weights:  32%|###2      | 33/103 [00:00<00:00, 1020.38it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]Loading weights:  32%|###2      | 33/103 [00:00<00:00, 1014.68it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]Loading weights:  33%|###3      | 34/103 [00:00<00:00, 1036.73it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    Loading weights:  33%|###3      | 34/103 [00:00<00:00, 1033.37it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]Loading weights:  34%|###3      | 35/103 [00:00<00:00, 1058.21it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]Loading weights:  34%|###3      | 35/103 [00:00<00:00, 1054.30it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]Loading weights:  35%|###4      | 36/103 [00:00<00:00, 1079.41it/s, Materializing param=encoder.layer.1.output.dense.bias]      Loading weights:  35%|###4      | 36/103 [00:00<00:00, 1076.04it/s, Materializing param=encoder.layer.1.output.dense.bias]Loading weights:  36%|###5      | 37/103 [00:00<00:00, 1101.12it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  36%|###5      | 37/103 [00:00<00:00, 1098.20it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  37%|###6      | 38/103 [00:00<00:00, 1121.91it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]Loading weights:  37%|###6      | 38/103 [00:00<00:00, 1119.02it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]Loading weights:  38%|###7      | 39/103 [00:00<00:00, 1141.78it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]Loading weights:  38%|###7      | 39/103 [00:00<00:00, 1136.43it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]Loading weights:  39%|###8      | 40/103 [00:00<00:00, 1156.71it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      Loading weights:  39%|###8      | 40/103 [00:00<00:00, 1152.19it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]Loading weights:  40%|###9      | 41/103 [00:00<00:00, 1173.05it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]Loading weights:  40%|###9      | 41/103 [00:00<00:00, 1169.67it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]Loading weights:  41%|####      | 42/103 [00:00<00:00, 1190.88it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      Loading weights:  41%|####      | 42/103 [00:00<00:00, 1187.26it/s, Materializing param=encoder.layer.2.attention.self.key.bias]Loading weights:  42%|####1     | 43/103 [00:00<00:00, 1204.97it/s, Materializing param=encoder.layer.2.attention.self.key.weight]Loading weights:  42%|####1     | 43/103 [00:00<00:00, 1200.97it/s, Materializing param=encoder.layer.2.attention.self.key.weight]Loading weights:  43%|####2     | 44/103 [00:00<00:00, 1218.26it/s, Materializing param=encoder.layer.2.attention.self.query.bias]Loading weights:  43%|####2     | 44/103 [00:00<00:00, 1212.71it/s, Materializing param=encoder.layer.2.attention.self.query.bias]Loading weights:  44%|####3     | 45/103 [00:00<00:00, 1230.33it/s, Materializing param=encoder.layer.2.attention.self.query.weight]Loading weights:  44%|####3     | 45/103 [00:00<00:00, 1225.83it/s, Materializing param=encoder.layer.2.attention.self.query.weight]Loading weights:  45%|####4     | 46/103 [00:00<00:00, 1244.09it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  Loading weights:  45%|####4     | 46/103 [00:00<00:00, 1238.57it/s, Materializing param=encoder.layer.2.attention.self.value.bias]Loading weights:  46%|####5     | 47/103 [00:00<00:00, 1259.35it/s, Materializing param=encoder.layer.2.attention.self.value.weight]Loading weights:  46%|####5     | 47/103 [00:00<00:00, 1255.76it/s, Materializing param=encoder.layer.2.attention.self.value.weight]Loading weights:  47%|####6     | 48/103 [00:00<00:00, 1277.39it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    Loading weights:  47%|####6     | 48/103 [00:00<00:00, 1273.83it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]Loading weights:  48%|####7     | 49/103 [00:00<00:00, 1294.97it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]Loading weights:  48%|####7     | 49/103 [00:00<00:00, 1291.22it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]Loading weights:  49%|####8     | 50/103 [00:00<00:00, 1312.05it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    Loading weights:  49%|####8     | 50/103 [00:00<00:00, 1309.03it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]Loading weights:  50%|####9     | 51/103 [00:00<00:00, 1329.45it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]Loading weights:  50%|####9     | 51/103 [00:00<00:00, 1326.34it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]Loading weights:  50%|#####     | 52/103 [00:00<00:00, 1347.28it/s, Materializing param=encoder.layer.2.output.dense.bias]      Loading weights:  50%|#####     | 52/103 [00:00<00:00, 1344.39it/s, Materializing param=encoder.layer.2.output.dense.bias]Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 1364.45it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 1360.69it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 1380.93it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 1377.84it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 1397.92it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 1394.72it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 1413.66it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 1410.65it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 1429.95it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 1426.12it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 1445.55it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 1442.36it/s, Materializing param=encoder.layer.3.attention.self.key.bias]Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 1461.10it/s, Materializing param=encoder.layer.3.attention.self.key.weight]Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 1457.74it/s, Materializing param=encoder.layer.3.attention.self.key.weight]Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 1476.71it/s, Materializing param=encoder.layer.3.attention.self.query.bias]Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 1473.05it/s, Materializing param=encoder.layer.3.attention.self.query.bias]Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 1491.96it/s, Materializing param=encoder.layer.3.attention.self.query.weight]Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 1488.80it/s, Materializing param=encoder.layer.3.attention.self.query.weight]Loading weights:  60%|######    | 62/103 [00:00<00:00, 1502.41it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  Loading weights:  60%|######    | 62/103 [00:00<00:00, 1497.53it/s, Materializing param=encoder.layer.3.attention.self.value.bias]Loading weights:  61%|######1   | 63/103 [00:00<00:00, 1514.02it/s, Materializing param=encoder.layer.3.attention.self.value.weight]Loading weights:  61%|######1   | 63/103 [00:00<00:00, 1508.69it/s, Materializing param=encoder.layer.3.attention.self.value.weight]Loading weights:  62%|######2   | 64/103 [00:00<00:00, 1522.93it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    Loading weights:  62%|######2   | 64/103 [00:00<00:00, 1517.33it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]Loading weights:  63%|######3   | 65/103 [00:00<00:00, 1530.28it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]Loading weights:  63%|######3   | 65/103 [00:00<00:00, 1524.36it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]Loading weights:  64%|######4   | 66/103 [00:00<00:00, 1538.97it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    Loading weights:  64%|######4   | 66/103 [00:00<00:00, 1534.09it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]Loading weights:  65%|######5   | 67/103 [00:00<00:00, 1547.31it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]Loading weights:  65%|######5   | 67/103 [00:00<00:00, 1542.51it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]Loading weights:  66%|######6   | 68/103 [00:00<00:00, 1556.01it/s, Materializing param=encoder.layer.3.output.dense.bias]      Loading weights:  66%|######6   | 68/103 [00:00<00:00, 1550.52it/s, Materializing param=encoder.layer.3.output.dense.bias]Loading weights:  67%|######6   | 69/103 [00:00<00:00, 1564.38it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  67%|######6   | 69/103 [00:00<00:00, 1559.48it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  68%|######7   | 70/103 [00:00<00:00, 1573.27it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]Loading weights:  68%|######7   | 70/103 [00:00<00:00, 1569.74it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]Loading weights:  69%|######8   | 71/103 [00:00<00:00, 1585.81it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]Loading weights:  69%|######8   | 71/103 [00:00<00:00, 1582.34it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]Loading weights:  70%|######9   | 72/103 [00:00<00:00, 1599.00it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      Loading weights:  70%|######9   | 72/103 [00:00<00:00, 1592.35it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]Loading weights:  71%|#######   | 73/103 [00:00<00:00, 1603.71it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]Loading weights:  71%|#######   | 73/103 [00:00<00:00, 1598.56it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 1611.58it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 1606.90it/s, Materializing param=encoder.layer.4.attention.self.key.bias]Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 1618.76it/s, Materializing param=encoder.layer.4.attention.self.key.weight]Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 1615.17it/s, Materializing param=encoder.layer.4.attention.self.key.weight]Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 1631.14it/s, Materializing param=encoder.layer.4.attention.self.query.bias]Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 1628.02it/s, Materializing param=encoder.layer.4.attention.self.query.bias]Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 1643.54it/s, Materializing param=encoder.layer.4.attention.self.query.weight]Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 1639.84it/s, Materializing param=encoder.layer.4.attention.self.query.weight]Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 1655.29it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 1652.12it/s, Materializing param=encoder.layer.4.attention.self.value.bias]Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 1668.08it/s, Materializing param=encoder.layer.4.attention.self.value.weight]Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 1665.08it/s, Materializing param=encoder.layer.4.attention.self.value.weight]Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 1680.85it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 1677.88it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 1693.87it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 1690.92it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 1704.00it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 1698.87it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]Loading weights:  81%|########  | 83/103 [00:00<00:00, 1710.46it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]Loading weights:  81%|########  | 83/103 [00:00<00:00, 1705.63it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]Loading weights:  82%|########1 | 84/103 [00:00<00:00, 1717.53it/s, Materializing param=encoder.layer.4.output.dense.bias]      Loading weights:  82%|########1 | 84/103 [00:00<00:00, 1712.29it/s, Materializing param=encoder.layer.4.output.dense.bias]Loading weights:  83%|########2 | 85/103 [00:00<00:00, 1723.14it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  83%|########2 | 85/103 [00:00<00:00, 1718.37it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  83%|########3 | 86/103 [00:00<00:00, 1730.02it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]Loading weights:  83%|########3 | 86/103 [00:00<00:00, 1724.94it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]Loading weights:  84%|########4 | 87/103 [00:00<00:00, 1735.08it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]Loading weights:  84%|########4 | 87/103 [00:00<00:00, 1729.74it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]Loading weights:  85%|########5 | 88/103 [00:00<00:00, 1740.41it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      Loading weights:  85%|########5 | 88/103 [00:00<00:00, 1735.93it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]Loading weights:  86%|########6 | 89/103 [00:00<00:00, 1746.72it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]Loading weights:  86%|########6 | 89/103 [00:00<00:00, 1741.54it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]Loading weights:  87%|########7 | 90/103 [00:00<00:00, 1752.60it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      Loading weights:  87%|########7 | 90/103 [00:00<00:00, 1747.25it/s, Materializing param=encoder.layer.5.attention.self.key.bias]Loading weights:  88%|########8 | 91/103 [00:00<00:00, 1759.36it/s, Materializing param=encoder.layer.5.attention.self.key.weight]Loading weights:  88%|########8 | 91/103 [00:00<00:00, 1756.09it/s, Materializing param=encoder.layer.5.attention.self.key.weight]Loading weights:  89%|########9 | 92/103 [00:00<00:00, 1770.16it/s, Materializing param=encoder.layer.5.attention.self.query.bias]Loading weights:  89%|########9 | 92/103 [00:00<00:00, 1767.28it/s, Materializing param=encoder.layer.5.attention.self.query.bias]Loading weights:  90%|######### | 93/103 [00:00<00:00, 1780.09it/s, Materializing param=encoder.layer.5.attention.self.query.weight]Loading weights:  90%|######### | 93/103 [00:00<00:00, 1776.74it/s, Materializing param=encoder.layer.5.attention.self.query.weight]Loading weights:  91%|#########1| 94/103 [00:00<00:00, 1790.59it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  Loading weights:  91%|#########1| 94/103 [00:00<00:00, 1787.16it/s, Materializing param=encoder.layer.5.attention.self.value.bias]Loading weights:  92%|#########2| 95/103 [00:00<00:00, 1795.98it/s, Materializing param=encoder.layer.5.attention.self.value.weight]Loading weights:  92%|#########2| 95/103 [00:00<00:00, 1791.42it/s, Materializing param=encoder.layer.5.attention.self.value.weight]Loading weights:  93%|#########3| 96/103 [00:00<00:00, 1800.60it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    Loading weights:  93%|#########3| 96/103 [00:00<00:00, 1795.68it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]Loading weights:  94%|#########4| 97/103 [00:00<00:00, 1808.47it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]Loading weights:  94%|#########4| 97/103 [00:00<00:00, 1805.57it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]Loading weights:  95%|#########5| 98/103 [00:00<00:00, 1817.94it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    Loading weights:  95%|#########5| 98/103 [00:00<00:00, 1814.52it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]Loading weights:  96%|#########6| 99/103 [00:00<00:00, 1827.77it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]Loading weights:  96%|#########6| 99/103 [00:00<00:00, 1824.87it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]Loading weights:  97%|#########7| 100/103 [00:00<00:00, 1835.82it/s, Materializing param=encoder.layer.5.output.dense.bias]     Loading weights:  97%|#########7| 100/103 [00:00<00:00, 1832.85it/s, Materializing param=encoder.layer.5.output.dense.bias]Loading weights:  98%|#########8| 101/103 [00:00<00:00, 1846.37it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  98%|#########8| 101/103 [00:00<00:00, 1843.58it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  99%|#########9| 102/103 [00:00<00:00, 1855.03it/s, Materializing param=pooler.dense.bias]                  Loading weights:  99%|#########9| 102/103 [00:00<00:00, 1850.64it/s, Materializing param=pooler.dense.bias]Loading weights: 100%|##########| 103/103 [00:00<00:00, 1860.65it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|##########| 103/103 [00:00<00:00, 1854.59it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|##########| 103/103 [00:00<00:00, 1845.47it/s, Materializing param=pooler.dense.weight]
[1mBertModel LOAD REPORT[0m from: sentence-transformers/all-MiniLM-L6-v2
Key                     | Status     |  | 
------------------------+------------+--+-
embeddings.position_ids | UNEXPECTED |  | 

[3mNotes:
- UNEXPECTED[3m	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.[0m
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/vocab.txt "HTTP/1.1 307 Temporary Redirect"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/vocab.txt "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/vocab.txt "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer.json "HTTP/1.1 307 Temporary Redirect"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/added_tokens.json "HTTP/1.1 404 Not Found"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/special_tokens_map.json "HTTP/1.1 307 Temporary Redirect"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/special_tokens_map.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/special_tokens_map.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/chat_template.jinja "HTTP/1.1 404 Not Found"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: GET https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|##########| 1/1 [00:00<00:00,  7.46it/s]Batches: 100%|##########| 1/1 [00:00<00:00,  7.44it/s]
Status 200
{
  "analysis": {
    "attack_prob": 0.6179830381308017,
    "embedding_max_sim": 0.9912694096565247,
    "heuristic": 0.2,
    "label": "attack",
    "model_proba": 0.7160063292395552,
    "threshold": 0.5
  },
  "ok": true
}
